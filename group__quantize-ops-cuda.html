<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>fbgemm_gpu: Quantization Operators (CUDA)</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">fbgemm_gpu
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search',false);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="doc-content">
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">Quantization Operators (CUDA)</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ga42277d094806afc9f23d52430c510105" id="r_ga42277d094806afc9f23d52430c510105"><td class="memItemLeft" align="right" valign="top">at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga42277d094806afc9f23d52430c510105">_float_to_bfloat16_gpu</a> (const at::Tensor &amp;input)</td></tr>
<tr class="separator:ga42277d094806afc9f23d52430c510105"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga52c8ee305990222b63257a431024e835" id="r_ga52c8ee305990222b63257a431024e835"><td class="memItemLeft" align="right" valign="top">at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga52c8ee305990222b63257a431024e835">_bfloat16_to_float_gpu</a> (const at::Tensor &amp;input)</td></tr>
<tr class="separator:ga52c8ee305990222b63257a431024e835"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaea7f718e5addaefa562e5a1f287c3de5" id="r_gaea7f718e5addaefa562e5a1f287c3de5"><td class="memItemLeft" align="right" valign="top">Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaea7f718e5addaefa562e5a1f287c3de5">_float_to_FP8rowwise_gpu</a> (const Tensor &amp;input, const bool forward)</td></tr>
<tr class="separator:gaea7f718e5addaefa562e5a1f287c3de5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaaf10540afa5cf8ca8805bb0e4c4e5492" id="r_gaaf10540afa5cf8ca8805bb0e4c4e5492"><td class="memItemLeft" align="right" valign="top">at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaaf10540afa5cf8ca8805bb0e4c4e5492">_FP8rowwise_to_float_gpu</a> (const at::Tensor &amp;input, bool forward, const int64_t output_dtype)</td></tr>
<tr class="separator:gaaf10540afa5cf8ca8805bb0e4c4e5492"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga50adb075977639eb15f0249751cb584d" id="r_ga50adb075977639eb15f0249751cb584d"><td class="memItemLeft" align="right" valign="top">Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga50adb075977639eb15f0249751cb584d">_float_to_fused8bitrowwise_gpu</a> (const Tensor &amp;input)</td></tr>
<tr class="separator:ga50adb075977639eb15f0249751cb584d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gace77836954555ee52abf3270e89f831d" id="r_gace77836954555ee52abf3270e89f831d"><td class="memItemLeft" align="right" valign="top">Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gace77836954555ee52abf3270e89f831d">_half_to_fused8bitrowwise_gpu</a> (const Tensor &amp;input)</td></tr>
<tr class="separator:gace77836954555ee52abf3270e89f831d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gace06316bba9b336a20b9de76ca38943b" id="r_gace06316bba9b336a20b9de76ca38943b"><td class="memItemLeft" align="right" valign="top">Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gace06316bba9b336a20b9de76ca38943b">_single_or_half_precision_to_fused8bitrowwise_gpu</a> (const Tensor &amp;input)</td></tr>
<tr class="separator:gace06316bba9b336a20b9de76ca38943b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga4eaebf19f2a7330fc060b085e540db42" id="r_ga4eaebf19f2a7330fc060b085e540db42"><td class="memItemLeft" align="right" valign="top">at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga4eaebf19f2a7330fc060b085e540db42">_fused8bitrowwise_to_float_gpu</a> (const at::Tensor &amp;input)</td></tr>
<tr class="separator:ga4eaebf19f2a7330fc060b085e540db42"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8193797bccd50ba869beefb87a14a9bd" id="r_ga8193797bccd50ba869beefb87a14a9bd"><td class="memItemLeft" align="right" valign="top">at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga8193797bccd50ba869beefb87a14a9bd">_fused8bitrowwise_to_half_gpu</a> (const at::Tensor &amp;input)</td></tr>
<tr class="separator:ga8193797bccd50ba869beefb87a14a9bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga29377cee5a9aca8c8ac1a38ce4a83ec1" id="r_ga29377cee5a9aca8c8ac1a38ce4a83ec1"><td class="memItemLeft" align="right" valign="top">at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga29377cee5a9aca8c8ac1a38ce4a83ec1">_fused8bitrowwise_to_single_or_half_precision_gpu</a> (const at::Tensor &amp;input, const int64_t output_dtype, const bool scale_bias_last, const bool quant_padding_float_type)</td></tr>
<tr class="separator:ga29377cee5a9aca8c8ac1a38ce4a83ec1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga304ba1cfb80e721f8c15cfa1db25621c" id="r_ga304ba1cfb80e721f8c15cfa1db25621c"><td class="memItemLeft" align="right" valign="top">at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga304ba1cfb80e721f8c15cfa1db25621c">_fused8bitrowwise_to_float_mixed_dim_gpu</a> (const at::Tensor &amp;input, const at::Tensor &amp;D_offsets, const int64_t output_dtype)</td></tr>
<tr class="separator:ga304ba1cfb80e721f8c15cfa1db25621c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae55e28033798a9a0cbd93c70b119c3aa" id="r_gae55e28033798a9a0cbd93c70b119c3aa"><td class="memItemLeft" align="right" valign="top">Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gae55e28033798a9a0cbd93c70b119c3aa">_float_to_fusednbitrowwise_gpu</a> (const Tensor &amp;input, const int64_t bit_rate)</td></tr>
<tr class="separator:gae55e28033798a9a0cbd93c70b119c3aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga399e3ece67cad23f6627ebf1f8127512" id="r_ga399e3ece67cad23f6627ebf1f8127512"><td class="memItemLeft" align="right" valign="top">at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga399e3ece67cad23f6627ebf1f8127512">_half_to_fusednbitrowwise_gpu</a> (const at::Tensor &amp;input, const int64_t bit_rate)</td></tr>
<tr class="separator:ga399e3ece67cad23f6627ebf1f8127512"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaae960240a6e2884a30205ed3fa9d3111" id="r_gaae960240a6e2884a30205ed3fa9d3111"><td class="memItemLeft" align="right" valign="top">Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaae960240a6e2884a30205ed3fa9d3111">_single_or_half_precision_to_fusednbitrowwise_gpu</a> (const Tensor &amp;input, const int64_t bit_rate)</td></tr>
<tr class="separator:gaae960240a6e2884a30205ed3fa9d3111"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga802490706abaca9d86d780bbdc0922cc" id="r_ga802490706abaca9d86d780bbdc0922cc"><td class="memItemLeft" align="right" valign="top">at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga802490706abaca9d86d780bbdc0922cc">_fusednbitrowwise_to_float_gpu</a> (const at::Tensor &amp;input, const int64_t bit_rate)</td></tr>
<tr class="separator:ga802490706abaca9d86d780bbdc0922cc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga756a59a6b84321e9b91af3e5f3334c31" id="r_ga756a59a6b84321e9b91af3e5f3334c31"><td class="memItemLeft" align="right" valign="top">at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga756a59a6b84321e9b91af3e5f3334c31">_fusednbitrowwise_to_half_gpu</a> (const at::Tensor &amp;input, const int64_t bit_rate)</td></tr>
<tr class="separator:ga756a59a6b84321e9b91af3e5f3334c31"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5ee877a3c135bd5160991c77ed170b23" id="r_ga5ee877a3c135bd5160991c77ed170b23"><td class="memItemLeft" align="right" valign="top">at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga5ee877a3c135bd5160991c77ed170b23">_fusednbitrowwise_to_single_or_half_precision_gpu</a> (const at::Tensor &amp;input, const int64_t bit_rate, const int64_t output_dtype)</td></tr>
<tr class="separator:ga5ee877a3c135bd5160991c77ed170b23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga4050ec86de055f06ad3a89c8b9cd24e9" id="r_ga4050ec86de055f06ad3a89c8b9cd24e9"><td class="memItemLeft" align="right" valign="top">at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga4050ec86de055f06ad3a89c8b9cd24e9">_float_to_hfp8_gpu</a> (const at::Tensor &amp;input, const int64_t ebits, const int64_t exponent_bias, const double max_pos)</td></tr>
<tr class="separator:ga4050ec86de055f06ad3a89c8b9cd24e9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga1dd6b70398b542022b236f4c576609a2" id="r_ga1dd6b70398b542022b236f4c576609a2"><td class="memItemLeft" align="right" valign="top">at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga1dd6b70398b542022b236f4c576609a2">_hfp8_to_float_gpu</a> (const at::Tensor &amp;input, const int64_t ebits, const int64_t exponent_bias)</td></tr>
<tr class="separator:ga1dd6b70398b542022b236f4c576609a2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga63e0eb01baaf7a680056549386bd17ec" id="r_ga63e0eb01baaf7a680056549386bd17ec"><td class="memItemLeft" align="right" valign="top">at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga63e0eb01baaf7a680056549386bd17ec">_float_to_msfp_gpu</a> (const at::Tensor &amp;input, const int64_t bounding_box_size, const int64_t ebits, const int64_t mbits, const int64_t bias, const double min_pos, const double max_pos)</td></tr>
<tr class="separator:ga63e0eb01baaf7a680056549386bd17ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6bf8bd180a3ed7174965bf73d18c3f2e" id="r_ga6bf8bd180a3ed7174965bf73d18c3f2e"><td class="memItemLeft" align="right" valign="top">at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga6bf8bd180a3ed7174965bf73d18c3f2e">_msfp_to_float_gpu</a> (const at::Tensor &amp;input, const int64_t ebits, const int64_t mbits, const int64_t bias)</td></tr>
<tr class="separator:ga6bf8bd180a3ed7174965bf73d18c3f2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5f9b9bdd22dba5a1870ef9c0e0877087" id="r_ga5f9b9bdd22dba5a1870ef9c0e0877087"><td class="memItemLeft" align="right" valign="top">Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga5f9b9bdd22dba5a1870ef9c0e0877087">_float_to_paddedFP8rowwise_gpu</a> (const Tensor &amp;input, const bool forward, const int64_t row_dim)</td></tr>
<tr class="separator:ga5f9b9bdd22dba5a1870ef9c0e0877087"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6c6d6fc1318239ecfaf902349a988cd6" id="r_ga6c6d6fc1318239ecfaf902349a988cd6"><td class="memItemLeft" align="right" valign="top">at::Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga6c6d6fc1318239ecfaf902349a988cd6">_paddedFP8rowwise_to_float_gpu</a> (const at::Tensor &amp;input, const bool forward, const int64_t row_dim, const int64_t output_last_dim, const int64_t output_dtype)</td></tr>
<tr class="separator:ga6c6d6fc1318239ecfaf902349a988cd6"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<h2 class="groupheader">Function Documentation</h2>
<a id="ga52c8ee305990222b63257a431024e835" name="ga52c8ee305990222b63257a431024e835"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga52c8ee305990222b63257a431024e835">&#9670;&#160;</a></span>_bfloat16_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _bfloat16_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of Brain Floating Point (<code>bfloat16</code>) values into a tensor of <code>float</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>bfloat16</code> values</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>float</code>. </dd></dl>

</div>
</div>
<a id="ga42277d094806afc9f23d52430c510105" name="ga42277d094806afc9f23d52430c510105"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga42277d094806afc9f23d52430c510105">&#9670;&#160;</a></span>_float_to_bfloat16_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _float_to_bfloat16_gpu </td>
          <td>(</td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>float</code> values into a tensor of Brain Floating Point (<code>bfloat16</code>) values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>float</code> values</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>bfloat16</code>. </dd></dl>

</div>
</div>
<a id="gaea7f718e5addaefa562e5a1f287c3de5" name="gaea7f718e5addaefa562e5a1f287c3de5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaea7f718e5addaefa562e5a1f287c3de5">&#9670;&#160;</a></span>_float_to_FP8rowwise_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Tensor _float_to_FP8rowwise_gpu </td>
          <td>(</td>
          <td class="paramtype">const Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const bool</td>          <td class="paramname"><span class="paramname"><em>forward</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>float</code> values into a tensor of <code>fp8</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>float</code> values. The dtype can be either <code>SparseType::FP32</code>, <code>SparseType::FP16</code>, or <code>SparseType::BF16</code> </td></tr>
    <tr><td class="paramname">forward</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>fp8</code>.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">c10::Error</td><td>if <code>input.dtype</code> is not one of (<code>SparseType::FP32</code>, <code>SparseType::FP16</code>, or <code>SparseType::BF16</code>). </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga50adb075977639eb15f0249751cb584d" name="ga50adb075977639eb15f0249751cb584d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga50adb075977639eb15f0249751cb584d">&#9670;&#160;</a></span>_float_to_fused8bitrowwise_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Tensor _float_to_fused8bitrowwise_gpu </td>
          <td>(</td>
          <td class="paramtype">const Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>float</code> values into a tensor of fused 8-bit rowwise values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>float</code> values</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to fused 8-bit rowwise. </dd></dl>

</div>
</div>
<a id="gae55e28033798a9a0cbd93c70b119c3aa" name="gae55e28033798a9a0cbd93c70b119c3aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae55e28033798a9a0cbd93c70b119c3aa">&#9670;&#160;</a></span>_float_to_fusednbitrowwise_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Tensor _float_to_fusednbitrowwise_gpu </td>
          <td>(</td>
          <td class="paramtype">const Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>bit_rate</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>float</code> values into a tensor of fused N-bit rowwise values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>float</code> values </td></tr>
    <tr><td class="paramname">bit_rate</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to fused N-bit rowwise. </dd></dl>

</div>
</div>
<a id="ga4050ec86de055f06ad3a89c8b9cd24e9" name="ga4050ec86de055f06ad3a89c8b9cd24e9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga4050ec86de055f06ad3a89c8b9cd24e9">&#9670;&#160;</a></span>_float_to_hfp8_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _float_to_hfp8_gpu </td>
          <td>(</td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>ebits</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>exponent_bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double</td>          <td class="paramname"><span class="paramname"><em>max_pos</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>float</code> values into a tensor of Hybrid 8-bit Floating Point (<code>hfp8</code>) values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>float</code> values </td></tr>
    <tr><td class="paramname">ebits</td><td></td></tr>
    <tr><td class="paramname">exponent_bias</td><td></td></tr>
    <tr><td class="paramname">max_pos</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>hfp8</code>.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">c10::Error</td><td>if <code>ebits &gt; 0</code> or <code>exponent_bias &gt; 0</code>. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga63e0eb01baaf7a680056549386bd17ec" name="ga63e0eb01baaf7a680056549386bd17ec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga63e0eb01baaf7a680056549386bd17ec">&#9670;&#160;</a></span>_float_to_msfp_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _float_to_msfp_gpu </td>
          <td>(</td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>bounding_box_size</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>ebits</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>mbits</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double</td>          <td class="paramname"><span class="paramname"><em>min_pos</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const double</td>          <td class="paramname"><span class="paramname"><em>max_pos</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>float</code> values into a tensor of Microsoft Floating Point (<code>msfp</code>) values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>float</code> values </td></tr>
    <tr><td class="paramname">bounding_box_size</td><td></td></tr>
    <tr><td class="paramname">ebits</td><td></td></tr>
    <tr><td class="paramname">mbits</td><td></td></tr>
    <tr><td class="paramname">bias</td><td></td></tr>
    <tr><td class="paramname">min_pos</td><td></td></tr>
    <tr><td class="paramname">max_pos</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>msfp</code>. </dd></dl>

</div>
</div>
<a id="ga5f9b9bdd22dba5a1870ef9c0e0877087" name="ga5f9b9bdd22dba5a1870ef9c0e0877087"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga5f9b9bdd22dba5a1870ef9c0e0877087">&#9670;&#160;</a></span>_float_to_paddedFP8rowwise_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Tensor _float_to_paddedFP8rowwise_gpu </td>
          <td>(</td>
          <td class="paramtype">const Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const bool</td>          <td class="paramname"><span class="paramname"><em>forward</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>row_dim</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>float</code> values into a tensor of padded <code>fp8</code> rowwise values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>float</code> values. The dtype can be either <code>SparseType::FP32</code>, <code>SparseType::FP16</code>, or <code>SparseType::BF16</code> </td></tr>
    <tr><td class="paramname">forward</td><td></td></tr>
    <tr><td class="paramname">row_dim</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to padded <code>fp8</code> rowwise. </dd></dl>

</div>
</div>
<a id="gaaf10540afa5cf8ca8805bb0e4c4e5492" name="gaaf10540afa5cf8ca8805bb0e4c4e5492"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaaf10540afa5cf8ca8805bb0e4c4e5492">&#9670;&#160;</a></span>_FP8rowwise_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _FP8rowwise_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>forward</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>output_dtype</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>fp8</code> values into a tensor of <code>float</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>fp8</code> values </td></tr>
    <tr><td class="paramname">forward</td><td></td></tr>
    <tr><td class="paramname">output_dtype</td><td>The target floating point type, specified as integer representation of <code>SparseType</code> enum</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>float</code> (with <code>dtype</code> of either <code>SparseType::FP32</code>, <code>SparseType::FP16</code>, or <code>SparseType::BF16</code>).</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">c10::Error</td><td>if <code>output_dtype</code> is not one of (<code>SparseType::FP32</code>, <code>SparseType::FP16</code>, or <code>SparseType::BF16</code>). </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga4eaebf19f2a7330fc060b085e540db42" name="ga4eaebf19f2a7330fc060b085e540db42"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga4eaebf19f2a7330fc060b085e540db42">&#9670;&#160;</a></span>_fused8bitrowwise_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _fused8bitrowwise_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of fused 8-bit rowwise values into a tensor of <code>float</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of fused 8-bit rowwise values</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>float</code>. </dd></dl>

</div>
</div>
<a id="ga304ba1cfb80e721f8c15cfa1db25621c" name="ga304ba1cfb80e721f8c15cfa1db25621c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga304ba1cfb80e721f8c15cfa1db25621c">&#9670;&#160;</a></span>_fused8bitrowwise_to_float_mixed_dim_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _fused8bitrowwise_to_float_mixed_dim_gpu </td>
          <td>(</td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>D_offsets</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>output_dtype</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of fused 8-bit rowwise values into a tensor of <code>at::kFloat</code> or <code>at::kHalf</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of fused 8-bit rowwise values </td></tr>
    <tr><td class="paramname">D_offsets</td><td></td></tr>
    <tr><td class="paramname">output_dtype</td><td>The target floating point type, specified as integer representation of <code>SparseType</code> enum</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>at::kFloat</code> or <code>at::kHalf</code>.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">c10::Error</td><td>if <code>output_dtype</code> is not one of (<code>SparseType::FP32</code>, <code>SparseType::FP16</code>) </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga8193797bccd50ba869beefb87a14a9bd" name="ga8193797bccd50ba869beefb87a14a9bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga8193797bccd50ba869beefb87a14a9bd">&#9670;&#160;</a></span>_fused8bitrowwise_to_half_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _fused8bitrowwise_to_half_gpu </td>
          <td>(</td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of fused 8-bit rowwise values into a tensor of <code>at::Half</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of fused 8-bit rowwise values</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>at::Half</code>. </dd></dl>

</div>
</div>
<a id="ga29377cee5a9aca8c8ac1a38ce4a83ec1" name="ga29377cee5a9aca8c8ac1a38ce4a83ec1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga29377cee5a9aca8c8ac1a38ce4a83ec1">&#9670;&#160;</a></span>_fused8bitrowwise_to_single_or_half_precision_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _fused8bitrowwise_to_single_or_half_precision_gpu </td>
          <td>(</td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>output_dtype</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const bool</td>          <td class="paramname"><span class="paramname"><em>scale_bias_last</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const bool</td>          <td class="paramname"><span class="paramname"><em>quant_padding_float_type</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of fused 8-bit rowwise values into a tensor of <code>float</code>, <code>at::Half</code>, or <code>at::BFloat16</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of fused 8-bit rowwise values </td></tr>
    <tr><td class="paramname">output_dtype</td><td>The target floating point type, specified as integer representation of <code>SparseType</code> enum</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>float</code>, <code>at::Half</code>, or <code>at::BFloat16</code>.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">c10::Error</td><td>if <code>output_dtype</code> is not one of (<code>SparseType::FP32</code>, <code>SparseType::FP16</code>, or <code>SparseType::BF16</code>). </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga802490706abaca9d86d780bbdc0922cc" name="ga802490706abaca9d86d780bbdc0922cc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga802490706abaca9d86d780bbdc0922cc">&#9670;&#160;</a></span>_fusednbitrowwise_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _fusednbitrowwise_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>bit_rate</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of fused N-bit rowwise values into a tensor of <code>float</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of fused N-bit rowwise values </td></tr>
    <tr><td class="paramname">bit_rate</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>float</code>. </dd></dl>

</div>
</div>
<a id="ga756a59a6b84321e9b91af3e5f3334c31" name="ga756a59a6b84321e9b91af3e5f3334c31"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga756a59a6b84321e9b91af3e5f3334c31">&#9670;&#160;</a></span>_fusednbitrowwise_to_half_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _fusednbitrowwise_to_half_gpu </td>
          <td>(</td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>bit_rate</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of fused N-bit rowwise values into a tensor of <code>at::Half</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of fused N-bit rowwise values </td></tr>
    <tr><td class="paramname">bit_rate</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>at::Half</code>. </dd></dl>

</div>
</div>
<a id="ga5ee877a3c135bd5160991c77ed170b23" name="ga5ee877a3c135bd5160991c77ed170b23"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga5ee877a3c135bd5160991c77ed170b23">&#9670;&#160;</a></span>_fusednbitrowwise_to_single_or_half_precision_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _fusednbitrowwise_to_single_or_half_precision_gpu </td>
          <td>(</td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>bit_rate</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>output_dtype</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of fused N-bit rowwise values into a tensor of <code>float</code> or <code>at::Half</code> or <code>at::Bf16</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of fused N-bit rowwise values </td></tr>
    <tr><td class="paramname">bit_rate</td><td></td></tr>
    <tr><td class="paramname">output_dtype</td><td>The target floating point type, specified as integer representation of <code>SparseType</code> enum</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>float</code> or <code>at::Half</code> or <code>at::Bf16</code>, depending on <code>output_dtype</code>.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">c10::Error</td><td>if <code>output_dtype</code> is not one of (<code>SparseType::FP32</code> or <code>SparseType::FP16</code> or <code>SparseType::BF16</code>). </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="gace77836954555ee52abf3270e89f831d" name="gace77836954555ee52abf3270e89f831d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gace77836954555ee52abf3270e89f831d">&#9670;&#160;</a></span>_half_to_fused8bitrowwise_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Tensor _half_to_fused8bitrowwise_gpu </td>
          <td>(</td>
          <td class="paramtype">const Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>at::Half</code> values into a tensor of fused 8-bit rowwise values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>at::Half</code> values</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to fused 8-bit rowwise. </dd></dl>

</div>
</div>
<a id="ga399e3ece67cad23f6627ebf1f8127512" name="ga399e3ece67cad23f6627ebf1f8127512"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga399e3ece67cad23f6627ebf1f8127512">&#9670;&#160;</a></span>_half_to_fusednbitrowwise_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _half_to_fusednbitrowwise_gpu </td>
          <td>(</td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>bit_rate</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>at::Half</code> values into a tensor of fused N-bit rowwise values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>at::Half</code> values </td></tr>
    <tr><td class="paramname">bit_rate</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to fused N-bit rowwise. </dd></dl>

</div>
</div>
<a id="ga1dd6b70398b542022b236f4c576609a2" name="ga1dd6b70398b542022b236f4c576609a2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga1dd6b70398b542022b236f4c576609a2">&#9670;&#160;</a></span>_hfp8_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _hfp8_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>ebits</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>exponent_bias</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of Hybrid 8-bit Floating Point (<code>hfp8</code>) values into a tensor of <code>float</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>hfp8</code> values </td></tr>
    <tr><td class="paramname">ebits</td><td></td></tr>
    <tr><td class="paramname">exponent_bias</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>float</code>.</dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">c10::Error</td><td>if <code>ebits &gt; 0</code> or <code>exponent_bias &gt; 0</code>. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga6bf8bd180a3ed7174965bf73d18c3f2e" name="ga6bf8bd180a3ed7174965bf73d18c3f2e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga6bf8bd180a3ed7174965bf73d18c3f2e">&#9670;&#160;</a></span>_msfp_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _msfp_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>ebits</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>mbits</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of Microsoft Floating Point (<code>msfp</code>) values into a tensor of <code>float</code> values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>msfp</code> values </td></tr>
    <tr><td class="paramname">ebits</td><td></td></tr>
    <tr><td class="paramname">mbits</td><td></td></tr>
    <tr><td class="paramname">bias</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to <code>float</code>. </dd></dl>

</div>
</div>
<a id="ga6c6d6fc1318239ecfaf902349a988cd6" name="ga6c6d6fc1318239ecfaf902349a988cd6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga6c6d6fc1318239ecfaf902349a988cd6">&#9670;&#160;</a></span>_paddedFP8rowwise_to_float_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">at::Tensor _paddedFP8rowwise_to_float_gpu </td>
          <td>(</td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const bool</td>          <td class="paramname"><span class="paramname"><em>forward</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>row_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>output_last_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>output_dtype</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of padded <code>fp8</code> rowwise values into a tensor of <code>float / values</code>. </p><pre class="fragment">@param input A tensor of `float` values.  The dtype can be either
             `SparseType::FP32`, `SparseType::FP16`, or `SparseType::BF16`
@param forward
@param row_dim
@param output_last_dim
@param output_dtype The target floating point type, specified as integer
                    representation of `SparseType` enum

@return A new tensor with values from the input tensor converted to `float`.

@throw c10::Error if `output_dtype` is not one of (`SparseType::FP32`,
`SparseType::FP16`, `SparseType::BF16`). 
</pre> 
</div>
</div>
<a id="gace06316bba9b336a20b9de76ca38943b" name="gace06316bba9b336a20b9de76ca38943b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gace06316bba9b336a20b9de76ca38943b">&#9670;&#160;</a></span>_single_or_half_precision_to_fused8bitrowwise_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Tensor _single_or_half_precision_to_fused8bitrowwise_gpu </td>
          <td>(</td>
          <td class="paramtype">const Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>at::Single</code> or <code>at::Half</code> values into a tensor of fused 8-bit rowwise values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>at::Single</code> or <code>at::Half</code> values</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to fused 8-bit rowwise. </dd></dl>

</div>
</div>
<a id="gaae960240a6e2884a30205ed3fa9d3111" name="gaae960240a6e2884a30205ed3fa9d3111"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaae960240a6e2884a30205ed3fa9d3111">&#9670;&#160;</a></span>_single_or_half_precision_to_fusednbitrowwise_gpu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Tensor _single_or_half_precision_to_fusednbitrowwise_gpu </td>
          <td>(</td>
          <td class="paramtype">const Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t</td>          <td class="paramname"><span class="paramname"><em>bit_rate</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Converts a tensor of <code>float</code> or <code>at::Half</code> values into a tensor of fused N-bit rowwise values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>A tensor of <code>float</code> or <code>at::Half</code> values </td></tr>
    <tr><td class="paramname">bit_rate</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with values from the input tensor converted to fused N-bit rowwise. </dd></dl>

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2
</small></address>
</div><!-- doc-content -->
</body>
</html>
